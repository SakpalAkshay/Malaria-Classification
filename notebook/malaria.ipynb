{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "# import pydot\n",
    "# from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Parasitized', 'Uninfected']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_names = [w for w in os.listdir(path + 'train/') if os.path.isdir(os.path.join(path + 'train/', w))]\n",
    "dir_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(path + 'valid/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sub folder for categories in valid folder\n",
    "for i in dir_names:\n",
    "    os.mkdir(path + 'valid/' + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving images in folder\n",
    "for d in dir_names:\n",
    "    g = glob(path + 'train/' + d + '/' + '*.png')\n",
    "    shuf = np.random.permutation(g)\n",
    "    \n",
    "    for i in range(int(len(g) / 5)): shutil.move(shuf[i], path + 'valid/' + d +'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 3\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1',\n",
    "                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(110, 110, 3), classes=2):\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(25, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape = (110, 110, 3), classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22048 images belonging to 2 classes.\n",
      "Found 5510 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "datagen = image.ImageDataGenerator()\n",
    "trn_batches = datagen.flow_from_directory('data/train/', target_size = (110, 110), \n",
    "                                          batch_size = batch_size, class_mode = 'categorical')\n",
    "val_batches = datagen.flow_from_directory('data/valid/', target_size = (110, 110), \n",
    "                                          batch_size = batch_size, class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../weights/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "220/220 [==============================] - 116s 526ms/step - loss: 0.9436 - acc: 0.6606 - val_loss: 0.3537 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88891, saving model to ../weights/weights-improvement-01-0.89.hdf5\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 104s 474ms/step - loss: 0.2563 - acc: 0.9224 - val_loss: 0.1719 - val_acc: 0.9398\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88891 to 0.93982, saving model to ../weights/weights-improvement-02-0.94.hdf5\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 104s 473ms/step - loss: 0.1485 - acc: 0.9504 - val_loss: 0.1510 - val_acc: 0.9456\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.93982 to 0.94564, saving model to ../weights/weights-improvement-03-0.95.hdf5\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 104s 474ms/step - loss: 0.1829 - acc: 0.9413 - val_loss: 0.1504 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94564 to 0.94673, saving model to ../weights/weights-improvement-04-0.95.hdf5\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 104s 474ms/step - loss: 0.1494 - acc: 0.9512 - val_loss: 0.1415 - val_acc: 0.9515\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.94673 to 0.95145, saving model to ../weights/weights-improvement-05-0.95.hdf5\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 104s 474ms/step - loss: 0.1289 - acc: 0.9556 - val_loss: 0.1406 - val_acc: 0.9496\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95145\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 104s 474ms/step - loss: 0.1275 - acc: 0.9550 - val_loss: 0.1805 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95145\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 105s 475ms/step - loss: 0.1293 - acc: 0.9546 - val_loss: 0.1280 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.95145 to 0.95618, saving model to ../weights/weights-improvement-08-0.96.hdf5\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 104s 475ms/step - loss: 0.1151 - acc: 0.9592 - val_loss: 0.1245 - val_acc: 0.9551\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95618\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 104s 475ms/step - loss: 0.1256 - acc: 0.9581 - val_loss: 0.1301 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95618\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 105s 475ms/step - loss: 0.1103 - acc: 0.9620 - val_loss: 0.1174 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.95618 to 0.95836, saving model to ../weights/weights-improvement-11-0.96.hdf5\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 104s 475ms/step - loss: 0.0949 - acc: 0.9660 - val_loss: 0.1296 - val_acc: 0.9589\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.95836 to 0.95891, saving model to ../weights/weights-improvement-12-0.96.hdf5\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 104s 475ms/step - loss: 0.0915 - acc: 0.9663 - val_loss: 0.1211 - val_acc: 0.9555\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95891\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 104s 475ms/step - loss: 0.0885 - acc: 0.9682 - val_loss: 0.1184 - val_acc: 0.9600\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.95891 to 0.96000, saving model to ../weights/weights-improvement-14-0.96.hdf5\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 104s 475ms/step - loss: 0.0827 - acc: 0.9709 - val_loss: 0.1214 - val_acc: 0.9596\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.96000\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 105s 476ms/step - loss: 0.0800 - acc: 0.9698 - val_loss: 0.1244 - val_acc: 0.9578\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.96000\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 104s 474ms/step - loss: 0.0802 - acc: 0.9707 - val_loss: 0.1241 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.96000\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 105s 477ms/step - loss: 0.0723 - acc: 0.9745 - val_loss: 0.1293 - val_acc: 0.9578\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.96000\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 104s 474ms/step - loss: 0.0708 - acc: 0.9746 - val_loss: 0.1435 - val_acc: 0.9565\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.96000\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 104s 475ms/step - loss: 0.0624 - acc: 0.9768 - val_loss: 0.1550 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.96000\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 104s 475ms/step - loss: 0.0644 - acc: 0.9765 - val_loss: 0.1517 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.96000\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 104s 474ms/step - loss: 0.0602 - acc: 0.9775 - val_loss: 0.1359 - val_acc: 0.9569\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.96000\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 104s 474ms/step - loss: 0.0559 - acc: 0.9794 - val_loss: 0.1405 - val_acc: 0.9565\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.96000\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 104s 474ms/step - loss: 0.0505 - acc: 0.9817 - val_loss: 0.1425 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.96000\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 104s 474ms/step - loss: 0.0435 - acc: 0.9840 - val_loss: 0.1777 - val_acc: 0.9529\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.96000\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 104s 475ms/step - loss: 0.0434 - acc: 0.9845 - val_loss: 0.1880 - val_acc: 0.9555\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.96000\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 104s 474ms/step - loss: 0.0426 - acc: 0.9845 - val_loss: 0.1400 - val_acc: 0.9573\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.96000\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 105s 475ms/step - loss: 0.0380 - acc: 0.9859 - val_loss: 0.1781 - val_acc: 0.9564\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.96000\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 104s 474ms/step - loss: 0.0346 - acc: 0.9883 - val_loss: 0.1639 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.96000\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 105s 475ms/step - loss: 0.0362 - acc: 0.9869 - val_loss: 0.1685 - val_acc: 0.9538\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.96000\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 104s 475ms/step - loss: 0.0292 - acc: 0.9895 - val_loss: 0.1831 - val_acc: 0.9555\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.96000\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 105s 476ms/step - loss: 0.0253 - acc: 0.9913 - val_loss: 0.2234 - val_acc: 0.9545\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.96000\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 105s 475ms/step - loss: 0.0209 - acc: 0.9928 - val_loss: 0.1924 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.96000\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 104s 473ms/step - loss: 0.0324 - acc: 0.9884 - val_loss: 0.2101 - val_acc: 0.9551\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.96000\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 105s 476ms/step - loss: 0.0254 - acc: 0.9914 - val_loss: 0.2081 - val_acc: 0.9587\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.96000\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 104s 474ms/step - loss: 0.0193 - acc: 0.9935 - val_loss: 0.2598 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.96000\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 104s 474ms/step - loss: 0.0214 - acc: 0.9924 - val_loss: 0.2108 - val_acc: 0.9545\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.96000\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 105s 475ms/step - loss: 0.0207 - acc: 0.9929 - val_loss: 0.2169 - val_acc: 0.9545\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.96000\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 104s 473ms/step - loss: 0.0196 - acc: 0.9933 - val_loss: 0.2494 - val_acc: 0.9487\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.96000\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 105s 475ms/step - loss: 0.0142 - acc: 0.9948 - val_loss: 0.2573 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.96000\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 104s 474ms/step - loss: 0.0190 - acc: 0.9936 - val_loss: 0.2545 - val_acc: 0.9538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00041: val_acc did not improve from 0.96000\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 103s 470ms/step - loss: 0.0171 - acc: 0.9936 - val_loss: 0.2191 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.96000\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 104s 471ms/step - loss: 0.0126 - acc: 0.9952 - val_loss: 0.2774 - val_acc: 0.9556\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.96000\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 104s 472ms/step - loss: 0.0131 - acc: 0.9947 - val_loss: 0.2529 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.96000\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 104s 471ms/step - loss: 0.0098 - acc: 0.9960 - val_loss: 0.2948 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.96000\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 104s 471ms/step - loss: 0.0145 - acc: 0.9947 - val_loss: 0.2257 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.96000\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 104s 471ms/step - loss: 0.0171 - acc: 0.9948 - val_loss: 0.2156 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.96000\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 104s 471ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.3059 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.96000 to 0.96164, saving model to ../weights/weights-improvement-48-0.96.hdf5\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 104s 472ms/step - loss: 0.0101 - acc: 0.9968 - val_loss: 0.2621 - val_acc: 0.9569\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.96164\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 103s 470ms/step - loss: 0.0132 - acc: 0.9954 - val_loss: 0.2664 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.96164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc51a574630>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(trn_batches, steps_per_epoch = trn_batches.n // batch_size, epochs = 50, \n",
    "                    validation_data = val_batches, validation_steps = val_batches.n // batch_size, \n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Images \n",
    "img = mpimg.imread(\"data/train/Parasitized/C100P61ThinF_IMG_20150918_144104_cell_162.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.resize(img, (110, 110, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.expand_dims(img, axis=0)\n",
    "image = preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_on_batch(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
